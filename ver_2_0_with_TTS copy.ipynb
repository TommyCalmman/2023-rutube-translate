{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SYAaAJtxfYIn"
      },
      "outputs": [],
      "source": [
        "!pip install -U openai-whisper\n",
        "!pip install moviepy\n",
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "79qDX4x2ffxw"
      },
      "outputs": [],
      "source": [
        "import whisper\n",
        "from moviepy.editor import VideoFileClip, concatenate_videoclips, concatenate_audioclips\n",
        "from pathlib import Path\n",
        "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
        "\n",
        "\n",
        "model_type_stt=\"medium\"\n",
        "# # Load the Whisper model\n",
        "model = whisper.load_model(model_type_stt)\n",
        "\n",
        "\n",
        "model_name = \"facebook/nllb-200-distilled-600M\"\n",
        "model_t = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "# nlp = spacy.load(\"xx_ent_wiki_sm\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sHvA4scBf44A"
      },
      "outputs": [],
      "source": [
        "d_langs_t = {'Английский': 'eng_Latn',\n",
        "            'Датский': 'dan_Latn',\n",
        "            'Испанский': 'spa_Latn',\n",
        "            'Итальянский': 'ita_Latn',\n",
        "            'Китайский': 'zho_Hans',\n",
        "            'Немецкий': 'deu_Latn',\n",
        "            'Польский': 'pol_Latn',\n",
        "            'Португальский': 'por_Latn',\n",
        "            'Турецкий': 'tur_Latn',\n",
        "            'Французский': 'fra_Latn',\n",
        "            'Чешский': 'ces_Latn',\n",
        "            # 'Японский': 'jpn_Jpan',\n",
        "            }\n",
        "\n",
        "d_langs_xtts = {'Английский': 'en',\n",
        "            'Датский': 'nl',\n",
        "            'Испанский': 'es',\n",
        "            'Итальянский': 'it',\n",
        "            'Китайский': 'zh-cn',\n",
        "            'Немецкий': 'de',\n",
        "            'Польский': 'pl',\n",
        "            'Португальский': 'pt',\n",
        "            'Турецкий': 'tr',\n",
        "            'Французский': 'fr',\n",
        "            'Чешский': 'cs',\n",
        "            # 'Японский': 'ja',\n",
        "            }\n",
        "\n",
        "def extract_audio_from_video(video_file, output_audio_format=\"mp3\"):\n",
        "    video = VideoFileClip(video_file)\n",
        "    audio_file = f\"{video_file.rsplit('.', 1)[0]}.{output_audio_format}\"\n",
        "    video.audio.write_audiofile(audio_file, logger=None)  # Disable logging for faster I/O\n",
        "    return audio_file\n",
        "\n",
        "def transcribe_with_whisper(audio_file, model=model):\n",
        "    # Transcribe the audio\n",
        "    result = model.transcribe(audio_file)\n",
        "    return result\n",
        "\n",
        "def speech2text(video_file):\n",
        "    audio_file = extract_audio_from_video(video_file)\n",
        "    data = transcribe_with_whisper(audio_file)\n",
        "    return {\n",
        "        'timecode_with_text': [[x['start'], x['end'], x['text']] for x in data['segments']],\n",
        "        'text': data['text']\n",
        "    }\n",
        "\n",
        "def cut_video(video_path, intervals):\n",
        "    video = VideoFileClip(video_path)\n",
        "    clips = []\n",
        "\n",
        "    start, end = intervals[0], intervals[1]\n",
        "    clip = video.subclip(start, end)\n",
        "    clips.append(clip)\n",
        "\n",
        "    return clips\n",
        "\n",
        "def concat_video_and_wav(clip):\n",
        "        # Load the video\n",
        "    # video = VideoFileClip(video_path)\n",
        "\n",
        "    # Load the audio file\n",
        "    audio = AudioFileClip('./wavs_for_xtts/wav_translated.wav')\n",
        "\n",
        "    # Set the audio of the video\n",
        "    return clip[0].set_audio(audio)\n",
        "# video_gen_path = '/content/Wav2Lip/results/result_voice.mp4'\n",
        "\n",
        "def get_wav_translate(text, path_to_speaker, lang):\n",
        "    # generate speech by cloning a voice using default settings\n",
        "    print(text, path_to_speaker, lang)\n",
        "    tts.tts_to_file(text=text,\n",
        "                    file_path=\"./wavs_for_xtts/wav_translated.wav\",\n",
        "                    speaker_wav=path_to_speaker,\n",
        "                    language=lang)\n",
        "\n",
        "def concatenate_to_wav(clips, path='./concat_wavs'):\n",
        "    audio_clips = []\n",
        "    for clip in clips:\n",
        "        audio_clips.append(clip.audio)\n",
        "    final_clip = concatenate_audioclips(audio_clips)\n",
        "    final_clip.write_audiofile(path + '/wav_after_concat.wav')\n",
        "\n",
        "def translate(text, target_language):\n",
        "    inputs = tokenizer(text, return_tensors=\"pt\")\n",
        "    outputs = model_t.generate(**inputs, forced_bos_token_id=tokenizer.lang_code_to_id[target_language])\n",
        "    return tokenizer.batch_decode(outputs, skip_special_tokens=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x9qnZ0KzgBDI"
      },
      "outputs": [],
      "source": [
        "from transformers import pipeline\n",
        "summarizer = pipeline(\"summarization\", model=\"facebook/bart-large-cnn\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def summarized_text(text, lang): \n",
        "    if lang != 'eng_Latn': \n",
        "        en_text = translate(text, 'eng_Latn') \n",
        "    else: \n",
        "        en_text = text \n",
        "    en_summ_text = summarizer(en_text, max_length=500, min_length=30, do_sample=False, truncation=True) \n",
        "    return translate(en_summ_text[0]['summary_text'], lang)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def main(video_file, lang='Английский', pathl=''):\n",
        "    lang_t = d_langs_t.get(lang, 'eng_Latn')\n",
        "    d_text_timecodes = speech2text(video_file)\n",
        "    #Path(f\"{pathl}/wavs_for_xtts\").mkdir(exist_ok = True)\n",
        "    #Path(f\"{pathl}/concat_wavs\").mkdir(exist_ok = True)\n",
        "    #Path(f\"{pathl}/result_videos\").mkdir(exist_ok = True)\n",
        "    with open(f'{pathl}/ru_text_full.txt', 'w') as f:\n",
        "      f.write(d_text_timecodes['text'])\n",
        "    with open(f'{pathl}/ru_subtitles.txt', 'w') as f:\n",
        "      for interval in d_text_timecodes['timecode_with_text']:\n",
        "        f.write(f'{interval[0]}, {interval[1]}, {interval[2]}\\n')\n",
        "    sum_text = summarized_text(d_text_timecodes['text'].lstrip(), lang_t)\n",
        "    with open(f'{pathl}/summarized.txt', 'w') as f:\n",
        "      f.write(str(sum_text[0]))\n",
        "    with open(f'{pathl}/{lang_t}_subtitles.txt', 'w') as f:\n",
        "      for interval in d_text_timecodes['timecode_with_text']:\n",
        "        f.write(f'{interval[0]}, {interval[1]}, {translate(interval[2], lang_t)[0]}\\n')\n",
        "    with open(f'{pathl}/{lang_t}_text.txt', 'w') as f:\n",
        "      f.write(translate(d_text_timecodes['text'].lstrip(), lang_t)[0])\n",
        "    return 'OK'\n",
        "\n",
        "\n",
        "# Example usage:\n",
        "if __name__ == \"__main__\":\n",
        "    tests = [(1, 'Английский'),\n",
        "             (13, 'Английский'),\n",
        "             (43, 'Английский'),\n",
        "             (45,'Английский'),\n",
        "             (32, 'Испанский'),\n",
        "             (3, 'Итальянский'),\n",
        "             (93, 'Итальянский'),\n",
        "             (0, 'Немецкий'),\n",
        "             (33, 'Немецкий'),\n",
        "             (35, 'Португальский'),\n",
        "             (41, 'Турецкий'),\n",
        "             (11, 'Французский'),\n",
        "             (2, 'Французский'),\n",
        "             (22, 'Французский'),\n",
        "    ]\n",
        "    for (num, lang) in tests:\n",
        "      #num = 64\n",
        "      pathl = f'/content/drive/MyDrive/dataset_rutube/{num}'\n",
        "      video_file = f\"{pathl}/{num}_orig.mp4\"  # Update with your video file path\n",
        "      #lang = 'Английский'\n",
        "      print(main(video_file, lang, pathl))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
